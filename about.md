---
layout: page
title: About
permalink: /about/
---

Building transformers and language models from scratch to understand how they work.

## Important: How I Write

My main motive is NOT to explain every single fucking piece of code. I show all the code, but I won't go into every tiny detail. I explain what each code block is doing at a high level - the big picture.

If you want to dive deep into specific functions or understand every line, just take that code block and throw it into ChatGPT or Claude. You can get all the details you want anytime. My job is to explain the concept, not write PyTorch documentation.

## Learning

- Neural networks (neurons, activation functions, backpropagation)
- Language models (bigrams to transformers)
- Attention mechanisms
- GPT architecture
- RLHF

## Links

- [GitHub](https://github.com/yashuatla1431)
- [Research Repo](https://github.com/yashuatla1431/research-transformers)
- yashwanthatla1431@gmail.com
